import os
import json
import requests
import tempfile
import tensorflow as tf
import keras
from keras.models import load_model
import keras.backend as K
import numpy as np
import time
from PIL import Image
import streamlit as st  # Ajout de l'import streamlit
from huggingface_hub import hf_hub_download

# Utilise TensorFlow comme backend pour Keras 3
os.environ['KERAS_BACKEND'] = 'tensorflow'

# Importer depuis utils.preprocessing au lieu d'autres modules
from utils.preprocessing import preprocess_image_for_convnext, resize_and_pad_image

# Configuration pour permettre la d√©s√©rialisation des couches Lambda
# keras.config.enable_unsafe_deserialization() car cette fonction n'est pas compatible avec v3 de keras.

# URL du mod√®le sur Hugging Face
HF_MODEL_URL = "https://huggingface.co/mourad42008/convnext-tiny-flipkart-classification/resolve/main/model_final_fixed.keras"  # MODIFICATION 1: .h5 ‚Üí .keras
# Nom du fichier pour la sauvegarde locale - CORRIG√â pour correspondre au fichier sur HF
MODEL_FILENAME = "model_final_fixed.keras"  # MODIFICATION 2: .h5 ‚Üí .keras

def get_hugging_face_token():
    """
    R√©cup√®re le token d'authentification Hugging Face depuis les secrets Streamlit
    ou une variable d'environnement.

    Returns:
        str: Le token d'authentification ou une cha√Æne vide si non trouv√©
    """
    # Essayer d'obtenir le token depuis les secrets Streamlit
    try:
        return st.secrets.get("HF_TOKEN", "")
    except:
        # Si ce n'est pas possible, essayer depuis les variables d'environnement
        return os.environ.get("HF_TOKEN", "")

def get_model_paths():
    """
    Obtient les chemins vers les fichiers du mod√®le.

    Returns:
        Dictionnaire contenant les chemins des fichiers
    """
    # R√©pertoire racine du projet
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

    # R√©pertoire pour les mod√®les
    models_dir = os.path.join(root_dir, "models", "saved")
    os.makedirs(models_dir, exist_ok=True)

    # Fichier du mod√®le - CORRIG√â pour utiliser le nouveau nom adapt√© au format SavedModel
    convnext_model_path = os.path.join(models_dir, MODEL_FILENAME)

    # Mapping des cat√©gories
    category_mapping = os.path.join(models_dir, "category_mapping.json")

    # Retourner les chemins
    return {
        "models_dir": models_dir,
        "convnext_model": convnext_model_path,
        "category_mapping": category_mapping
    }

# Variable globale pour stocker le placeholder de chargement
loading_placeholder = None

def set_loading_placeholder(placeholder):
    """
    D√©finit le placeholder pour afficher les messages de progression

    Args:
        placeholder: √âl√©ment Streamlit pour afficher les messages de progression
    """
    global loading_placeholder
    loading_placeholder = placeholder

def update_loading_status(message, status="info"):
    """
    Met √† jour le statut de chargement dans l'interface Streamlit

    Args:
        message: Message √† afficher
        status: Type de message ('info', 'success', 'error', 'warning')
    """
    global loading_placeholder
    if loading_placeholder is not None:
        if status == "info":
            loading_placeholder.info(message)
        elif status == "success":
            loading_placeholder.success(message)
        elif status == "error":
            loading_placeholder.error(message)
        elif status == "warning":
            loading_placeholder.warning(message)
    else:
        print(message)  # Fallback √† un print normal si placeholder non d√©fini

# MODIFICATION : Ligne 104 comment√©e comme demand√©
# @st.cache_resource(show_spinner=False)
def load_model_from_huggingface():
    """
    Charge le mod√®le depuis Hugging Face avec affichage de l'√©tat de progression
    dans l'interface Streamlit.

    Returns:
        Mod√®le Keras charg√©
    """
    # AJOUT DEBUG - D√âBUT
    st.write("üîç DEBUG: Entr√©e dans load_model_from_huggingface")
    # FIN AJOUT

    try:
        # Obtenir les chemins
        paths = get_model_paths()
        model_path = paths["convnext_model"]

        # AJOUT DEBUG - D√âBUT
        st.write(f"üîç DEBUG: model_path = {model_path}")
        # FIN AJOUT

        # Si le mod√®le existe d√©j√† localement, le charger
        if os.path.exists(model_path):
            # AJOUT DEBUG - D√âBUT
            st.write("üîç DEBUG: Mod√®le local trouv√©")
            # FIN AJOUT

            update_loading_status(f"Chargement du mod√®le local depuis {model_path}...")
            try:
                # Pour un SavedModel, utiliser keras.models.load_model directement
                model = keras.models.load_model(model_path)
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Mod√®le local charg√© avec succ√®s", "error")
                # FIN AJOUT
                update_loading_status("Mod√®le local charg√© avec succ√®s!", "success")
                return model
            except ValueError as e:
                # AJOUT DEBUG - D√âBUT
                update_loading_status(f"üîç DEBUG: Erreur chargement local = {e}", "error")
                # FIN AJOUT
                update_loading_status(f"Erreur standard de chargement: {e}", "warning")
                update_loading_status("Tentative de chargement avec TFSMLayer...")
                try:
                    # Utiliser TFSMLayer pour charger un SavedModel format
                    from keras.layers import TFSMLayer
                    from keras.models import Sequential

                    # Cr√©er un mod√®le qui charge le SavedModel en tant que couche
                    model = Sequential([
                        TFSMLayer(model_path, call_endpoint='serving_default')
                    ])
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status("üîç DEBUG: Mod√®le charg√© avec TFSMLayer", "error")
                    # FIN AJOUT
                    update_loading_status("Mod√®le charg√© avec TFSMLayer!", "success")
                    return model
                except Exception as inner_e:
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status(f"üîç DEBUG: Erreur TFSMLayer = {inner_e}", "error")
                    # FIN AJOUT
                    update_loading_status(f"Erreur avec TFSMLayer: {inner_e}", "error")

                    # Derni√®re tentative avec un chargement diff√©rent
                    try:
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status("üîç DEBUG: Tentative tf.saved_model.load", "error")
                        # FIN AJOUT
                        update_loading_status("Tentative de chargement direct avec tf.saved_model.load...", "info")
                        model = tf.saved_model.load(model_path)
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status("üîç DEBUG: tf.saved_model.load r√©ussi", "error")
                        # FIN AJOUT
                        update_loading_status("Mod√®le charg√© avec tf.saved_model.load!", "success")
                        return model
                    except Exception as sm_e:
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status(f"üîç DEBUG: Erreur tf.saved_model.load = {sm_e}", "error")
                        # FIN AJOUT
                        update_loading_status(f"Erreur avec tf.saved_model.load: {sm_e}", "error")
                        return None

        # Sinon, t√©l√©charger le mod√®le depuis Hugging Face
        # AJOUT DEBUG - D√âBUT
        st.write("üîç DEBUG: Pas de mod√®le local, t√©l√©chargement depuis HF")
        # FIN AJOUT
        update_loading_status(f"T√©l√©chargement du mod√®le depuis Hugging Face...", "info")

        # Cr√©er un fichier temporaire pour le t√©l√©chargement
        with tempfile.NamedTemporaryFile(delete=False) as temp_file:
            temp_path = temp_file.name

        # AJOUT DEBUG - D√âBUT
        update_loading_status(f"üîç DEBUG: temp_path = {temp_path}", "error")
        # FIN AJOUT

        # Obtenir le token d'authentification
        hf_token = get_hugging_face_token()

        # Pr√©parer les headers avec le token si disponible
        headers = {}
        if hf_token:
            headers["Authorization"] = f"Bearer {hf_token}"
            # AJOUT DEBUG - D√âBUT
            update_loading_status("üîç DEBUG: Token trouv√© et utilis√©", "error")
            # FIN AJOUT
            update_loading_status("Token d'authentification Hugging Face trouv√© et utilis√©", "info")
        else:
            # AJOUT DEBUG - D√âBUT
            update_loading_status("üîç DEBUG: Aucun token trouv√©", "error")
            # FIN AJOUT
            update_loading_status("Aucun token d'authentification Hugging Face trouv√©", "warning")

        # Utiliser hf_hub_download au lieu de requests.get
        # AJOUT DEBUG - D√âBUT
        update_loading_status("üîç DEBUG: D√©but du t√©l√©chargement avec hf_hub_download", "error")
        # FIN AJOUT
        try:
            # T√©l√©charger avec hf_hub_download et force_download=True
            model_path_downloaded = hf_hub_download(
                repo_id="mourad42008/convnext-tiny-flipkart-classification",
                filename="model_final_fixed.keras",
                force_download=True,  # ‚Üê AJOUT ESSENTIEL
                token=hf_token,
                cache_dir=tempfile.gettempdir()
            )
            
            # Copier vers temp_path pour le reste du code
            import shutil
            shutil.copy2(model_path_downloaded, temp_path)
            downloaded = os.path.getsize(temp_path)
            
            update_loading_status(f"T√©l√©chargement termin√©: {downloaded/1024/1024:.1f} MB", "success")
            
        except Exception as e:
            update_loading_status(f"Erreur t√©l√©chargement: {e}", "error")
            return None

        # AJOUT DEBUG - D√âBUT
        st.write(f"üîç DEBUG: T√©l√©chargement termin√©, taille = {downloaded} bytes")
        # FIN AJOUT
        update_loading_status("T√©l√©chargement termin√©. Chargement du mod√®le...", "info")

        # V√©rifier si le fichier t√©l√©charg√© est un SavedModel ou autre format
        try:
            # AJOUT DEBUG - D√âBUT
            update_loading_status("üîç DEBUG: V√©rification du format", "error")
            # FIN AJOUT
            # Essayer d'abord avec tf.saved_model.load pour d√©tecter si c'est un SavedModel
            update_loading_status("V√©rification du format du mod√®le...", "info")
            saved_model = tf.saved_model.contains_saved_model(temp_path)
            # AJOUT DEBUG - D√âBUT
            update_loading_status(f"üîç DEBUG: Is SavedModel = {saved_model}", "error")
            # FIN AJOUT
            if saved_model:
                update_loading_status("Mod√®le d√©tect√© comme format SavedModel", "info")
                try:
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status("üîç DEBUG: Tentative tf.saved_model.load", "error")
                    # FIN AJOUT
                    model = tf.saved_model.load(temp_path)
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status("üîç DEBUG: tf.saved_model.load r√©ussi", "error")
                    # FIN AJOUT
                    update_loading_status("Mod√®le charg√© avec tf.saved_model.load!", "success")
                except Exception as sm_e:
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status(f"üîç DEBUG: Erreur tf.saved_model.load = {sm_e}", "error")
                    # FIN AJOUT
                    update_loading_status(f"Erreur avec tf.saved_model.load: {sm_e}", "error")
                    # Essayer avec une approche plus standard pour les SavedModel
                    try:
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status("üîç DEBUG: Tentative keras.models.load_model", "error")
                        # FIN AJOUT
                        model = keras.models.load_model(temp_path)
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status("üîç DEBUG: keras.models.load_model r√©ussi", "error")
                        # FIN AJOUT
                        update_loading_status("Mod√®le charg√© avec keras.models.load_model!", "success")
                    except Exception as keras_e:
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status(f"üîç DEBUG: Erreur keras.models.load_model = {keras_e}", "error")
                        # FIN AJOUT
                        update_loading_status(f"Erreur avec keras.models.load_model: {keras_e}", "error")
                        # Utiliser TFSMLayer comme indiqu√© dans l'erreur
                        try:
                            # AJOUT DEBUG - D√âBUT
                            update_loading_status("üîç DEBUG: Tentative TFSMLayer pour le fichier t√©l√©charg√©", "error")
                            # FIN AJOUT
                            update_loading_status("Tentative de chargement avec TFSMLayer...", "info")
                            from keras.layers import TFSMLayer
                            from keras.models import Sequential
                            
                            # Cr√©er un mod√®le avec TFSMLayer
                            model = Sequential([
                                TFSMLayer(temp_path, call_endpoint='serving_default')
                            ])
                            # AJOUT DEBUG - D√âBUT
                            update_loading_status("üîç DEBUG: TFSMLayer r√©ussi pour le fichier t√©l√©charg√©", "error")
                            # FIN AJOUT
                            update_loading_status("Mod√®le charg√© avec TFSMLayer!", "success")
                        except Exception as tfsm_e:
                            # AJOUT DEBUG - D√âBUT
                            update_loading_status(f"üîç DEBUG: Erreur TFSMLayer pour le fichier t√©l√©charg√© = {tfsm_e}", "error")
                            # FIN AJOUT
                            update_loading_status(f"Erreur avec TFSMLayer: {tfsm_e}", "error")
                            return None
            else:
                # Si ce n'est pas un SavedModel, essayer avec les m√©thodes standard Keras
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Tentative load_model standard", "error")
                # FIN AJOUT
                update_loading_status("Mod√®le n'est pas un SavedModel, tentative avec load_model standard...", "info")
                try:
                    model = keras.models.load_model(temp_path)
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status("üîç DEBUG: load_model standard r√©ussi", "error")
                    # FIN AJOUT
                    update_loading_status("Mod√®le charg√© avec keras.models.load_model standard!", "success")
                except Exception as keras_e:
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status(f"üîç DEBUG: Erreur load_model standard = {keras_e}", "error")
                    # FIN AJOUT
                    update_loading_status(f"Erreur avec load_model standard: {keras_e}", "error")
                    # Utiliser TFSMLayer comme indiqu√© dans l'erreur
                    try:
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status("üîç DEBUG: Tentative TFSMLayer en fallback", "error")
                        # FIN AJOUT
                        update_loading_status("Tentative de chargement avec TFSMLayer en tant que fallback...", "info")
                        from keras.layers import TFSMLayer
                        from keras.models import Sequential
                        
                        # Cr√©er un mod√®le avec TFSMLayer
                        model = Sequential([
                            TFSMLayer(temp_path, call_endpoint='serving_default')
                        ])
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status("üîç DEBUG: TFSMLayer fallback r√©ussi", "error")
                        # FIN AJOUT
                        update_loading_status("Mod√®le charg√© avec TFSMLayer (fallback)!", "success")
                    except Exception as tfsm_e:
                        # AJOUT DEBUG - D√âBUT
                        update_loading_status(f"üîç DEBUG: Erreur TFSMLayer fallback = {tfsm_e}", "error")
                        # FIN AJOUT
                        update_loading_status(f"Erreur avec TFSMLayer fallback: {tfsm_e}", "error")
                        return None
        except Exception as format_e:
            # AJOUT DEBUG - D√âBUT
            update_loading_status(f"üîç DEBUG: Erreur v√©rification format = {format_e}", "error")
            # FIN AJOUT
            update_loading_status(f"Erreur lors de la v√©rification du format: {format_e}", "error")
            # Derni√®re tentative avec la m√©thode standard
            try:
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Derni√®re tentative load_model", "error")
                # FIN AJOUT
                model = keras.models.load_model(temp_path)
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Derni√®re tentative r√©ussie", "error")
                # FIN AJOUT
                update_loading_status("Mod√®le charg√© avec keras.models.load_model (derni√®re tentative)!", "success")
            except Exception as last_e:
                # AJOUT DEBUG - D√âBUT
                update_loading_status(f"üîç DEBUG: Derni√®re tentative √©chou√©e = {last_e}", "error")
                # FIN AJOUT
                update_loading_status(f"√âchec de toutes les tentatives de chargement: {last_e}", "error")
                # Ultime tentative avec TFSMLayer
                try:
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status("üîç DEBUG: Ultime tentative TFSMLayer", "error")
                    # FIN AJOUT
                    update_loading_status("Ultime tentative avec TFSMLayer...", "info")
                    from keras.layers import TFSMLayer
                    from keras.models import Sequential
                    
                    # Cr√©er un mod√®le avec TFSMLayer
                    model = Sequential([
                        TFSMLayer(temp_path, call_endpoint='serving_default')
                    ])
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status("üîç DEBUG: Ultime tentative TFSMLayer r√©ussie", "error")
                    # FIN AJOUT
                    update_loading_status("Mod√®le charg√© avec TFSMLayer (ultime tentative)!", "success")
                except Exception as final_e:
                    # AJOUT DEBUG - D√âBUT
                    update_loading_status(f"üîç DEBUG: Ultime tentative TFSMLayer √©chou√©e = {final_e}", "error")
                    # FIN AJOUT
                    update_loading_status(f"√âchec ultime avec TFSMLayer: {final_e}", "error")
                    return None

        # Sauvegarder le mod√®le localement pour une utilisation future
        try:
            # AJOUT DEBUG - D√âBUT
            update_loading_status("üîç DEBUG: D√©but sauvegarde locale", "error")
            # FIN AJOUT
            update_loading_status(f"Sauvegarde du mod√®le vers {model_path}...", "info")
            # Utiliser keras.models.save pour un format compatible
            if hasattr(model, 'save'):
                model.save(model_path)
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Sauvegarde avec model.save() r√©ussie", "error")
                # FIN AJOUT
            else:
                tf.saved_model.save(model, model_path)
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Sauvegarde avec tf.saved_model.save() r√©ussie", "error")
                # FIN AJOUT
            update_loading_status("Mod√®le sauvegard√© localement avec succ√®s!", "success")
        except Exception as save_e:
            # AJOUT DEBUG - D√âBUT
            update_loading_status(f"üîç DEBUG: Erreur sauvegarde = {save_e}", "error")
            # FIN AJOUT
            update_loading_status(f"Erreur lors de la sauvegarde du mod√®le: {save_e}", "warning")
            # Copier le fichier temporaire comme alternative
            import shutil
            try:
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Tentative copie fichier", "error")
                # FIN AJOUT
                update_loading_status("Tentative de copie du fichier temporaire...", "info")
                shutil.copy2(temp_path, model_path)
                # AJOUT DEBUG - D√âBUT
                update_loading_status("üîç DEBUG: Copie fichier r√©ussie", "error")
                # FIN AJOUT
                update_loading_status("Fichier temporaire copi√© avec succ√®s!", "success")
            except Exception as copy_e:
                # AJOUT DEBUG - D√âBUT
                update_loading_status(f"üîç DEBUG: Erreur copie = {copy_e}", "error")
                # FIN AJOUT
                update_loading_status(f"Erreur lors de la copie du fichier: {copy_e}", "error")

        # Supprimer le fichier temporaire
        try:
            os.unlink(temp_path)
            # AJOUT DEBUG - D√âBUT
            update_loading_status("üîç DEBUG: Fichier temporaire supprim√©", "error")
            # FIN AJOUT
        except Exception as e:
            # AJOUT DEBUG - D√âBUT
            update_loading_status(f"üîç DEBUG: Erreur suppression temp = {e}", "error")
            # FIN AJOUT
            pass

        # AJOUT DEBUG - D√âBUT
        st.write(f"üîç DEBUG: Retour du mod√®le = {model}, type = {type(model)}")
        # FIN AJOUT
        return model

    except Exception as e:
        import traceback
        # AJOUT DEBUG - D√âBUT
        update_loading_status(f"üîç DEBUG: Exception g√©n√©rale = {e}", "error")
        # FIN AJOUT
        update_loading_status(f"Erreur lors du chargement du mod√®le: {e}", "error")
        update_loading_status(traceback.format_exc(), "error")

        # Ajouter plus de d√©tails sur l'erreur
        try:
            if 'response' in locals() and response is not None:
                update_loading_status(f"Code d'√©tat HTTP: {response.status_code}", "error")
                update_loading_status(f"URL finale: {response.url}", "error")
        except:
            pass

        # AJOUT DEBUG - D√âBUT
        update_loading_status("üîç DEBUG: Retour None √† cause de l'exception", "error")
        # FIN AJOUT
        return None

def load_efficientnet_transformer_model(progress_placeholder=None):
    """
    Charge le mod√®le EfficientNet-Transformer (maintenu pour compatibilit√©,
    mais charge r√©ellement ConvNeXtTiny).

    Args:
        progress_placeholder: Un placeholder Streamlit pour afficher la progression

    Returns:
        Mod√®le Keras charg√©
    """
    # AJOUT DEBUG - D√âBUT
    st.write("üîç DEBUG: Entr√©e dans load_efficientnet_transformer_model")
    # FIN AJOUT

    # D√©finir le placeholder de chargement si fourni
    if progress_placeholder is not None:
        set_loading_placeholder(progress_placeholder)

    update_loading_status("Chargement du mod√®le ConvNeXtTiny...", "info")

    # AJOUT DEBUG - D√âBUT
    st.write("üîç DEBUG: Appel load_model_from_huggingface")
    # FIN AJOUT

    # AJOUT DEBUG 1: Debug du d√©but de chargement
    update_loading_status("D√©but de load_model_from_huggingface...", "info")
    model = load_model_from_huggingface()
    # MODIFICATION : ajout de st.write() pour plus de visibilit√©
    st.write(f"üîç DEBUG: Mod√®le retourn√© = {model}, type = {type(model)}")
    update_loading_status(f"Mod√®le retourn√© de HF: {model}", "info")

    if model is None:
        update_loading_status("Impossible de charger le mod√®le. V√©rifiez la connexion et les chemins.", "error")
        # AJOUT DEBUG - D√âBUT
        update_loading_status("üîç DEBUG: model is None - Sortie avec None", "error")
        # FIN AJOUT
    else:
        update_loading_status("Mod√®le charg√© avec succ√®s!", "success")
        # AJOUT DEBUG 2: Informations suppl√©mentaires sur le mod√®le
        update_loading_status(f"Type du mod√®le: {type(model)}", "info")
        if hasattr(model, 'layers'):
            update_loading_status(f"Nombre de couches: {len(model.layers)}", "info")
        # AJOUT DEBUG - D√âBUT
        update_loading_status("üîç DEBUG: Mod√®le charg√© - Retour du mod√®le", "error")
        # FIN AJOUT

    return model

def load_categories():
    """
    Charge les cat√©gories de classification.

    Returns:
        Dictionnaire des cat√©gories {indice: nom}
    """
    paths = get_model_paths()
    category_file = paths["category_mapping"]

    # Si le fichier de mapping existe, le charger
    if os.path.exists(category_file):
        try:
            with open(category_file, 'r') as f:
                mapping_data = json.load(f)

            # V√©rifier la structure du fichier
            if "categories" in mapping_data:
                return {int(k): v for k, v in mapping_data["categories"].items()}
        except Exception as e:
            print(f"Erreur lors du chargement des cat√©gories: {e}")

    # Cat√©gories par d√©faut
    default_categories = {
        0: "Baby Care",
        1: "Beauty and Personal Care",
        2: "Computers",
        3: "Home Decor & Festive Needs",
        4: "Home Furnishing",
        5: "Kitchen & Dining",
        6: "Watches"
    }

    # Sauvegarder les cat√©gories par d√©faut pour une utilisation future
    try:
        os.makedirs(os.path.dirname(category_file), exist_ok=True)
        with open(category_file, 'w') as f:
            json.dump({"categories": default_categories}, f, indent=2)
    except Exception as e:
        print(f"Erreur lors de la sauvegarde des cat√©gories: {e}")

    return default_categories

def preprocess_image(image, target_size=(224, 224)):
    """
    Pr√©traite une image pour l'inf√©rence.
    Cette fonction est maintenue pour compatibilit√©, mais utilise maintenant
    preprocess_image_for_convnext en interne.

    Args:
        image: Image PIL
        target_size: Taille cible (d√©faut: 224x224)

    Returns:
        Tableau numpy normalis√© pr√™t pour l'inf√©rence
    """
    print("ATTENTION: preprocess_image est obsol√®te, utilisez preprocess_image_for_convnext √† la place")
    return preprocess_image_for_convnext(image, target_size)

# Si ex√©cut√© directement, tester le chargement du mod√®le
if __name__ == "__main__":
    # Cr√©ation d'un placeholder pour les tests
    test_placeholder = None
    if 'st' in globals():
        test_placeholder = st.empty()

    model = load_efficientnet_transformer_model(test_placeholder)
    categories = load_categories()
    print(f"Cat√©gories: {categories}")

    if model:
        print(f"Mod√®le charg√© avec succ√®s. Nombre de couches: {len(model.layers) if hasattr(model, 'layers') else 'N/A (SavedModel format)'}")
