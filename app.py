import streamlit as st
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import io
import time
import glob
import random
import traceback
import json
import requests
import sys
import platform
import psutil

from models.model_loader import load_efficientnet_transformer_model, load_categories, get_model_paths, get_hugging_face_token, HF_MODEL_URL
from models.inference import predict_image
from utils.visualization import plot_prediction_bars
from utils.preprocessing import resize_and_pad_image, apply_data_augmentation

# Configuration de la page avec pr√©occupation d'accessibilit√©
st.set_page_config(
    page_title="Classification d'Images - ConvNeXtTiny",
    page_icon="ü¶ú",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ajout de CSS pour am√©liorer l'accessibilit√©
st.markdown("""
<style>
    /* Augmenter le contraste des textes */
    .stMarkdown, .stText, .stHeading, .stButton, .stRadio, h1, h2, h3, p {
        color: #191919 !important;
    }
    
    /* Augmenter la taille de la police pour une meilleure lisibilit√© */
    .stMarkdown, .stText, p {
        font-size: 16px !important;
    }
    
    /* Meilleur contraste pour les titres */
    h1, h2, h3, .stHeading {
        font-weight: 600 !important;
    }
    
    /* Assurer que les liens sont facilement identifiables */
    a {
        color: #0056b3 !important;
        text-decoration: underline !important;
    }
    
    /* Focus visible pour les √©l√©ments interactifs */
    button:focus, input:focus, select:focus {
        outline: 3px solid #4299e1 !important;
    }
    
    /* Am√©liorer la visibilit√© des boutons */
    .stButton button {
        font-weight: 500 !important;
        padding: 0.5rem 1rem !important;
    }
    
    /* Meilleur espacement pour les √©l√©ments de formulaire */
    .stRadio, .stSelectbox, .stFileUploader {
        margin-bottom: 1.5rem !important;
    }
</style>
""", unsafe_allow_html=True)

def test_hugging_face_connection():
    """
    Teste la connexion √† Hugging Face en v√©rifiant l'acc√®s au mod√®le.
    """
    try:
        # Obtenir le token
        hf_token = get_hugging_face_token()

        # Pr√©parer les headers
        headers = {}
        if hf_token:
            headers["Authorization"] = f"Bearer {hf_token}"
            st.info("üîë Token d'authentification trouv√©")
        else:
            st.warning("‚ö†Ô∏è Aucun token d'authentification trouv√©")

        # Faire la requ√™te - Utiliser GET au lieu de HEAD et suivre les redirections
        with st.spinner("Test de connexion en cours. Veuillez patienter..."):
            # Test direct sur le mod√®le avec GET et streaming
            response = requests.get(
                HF_MODEL_URL,
                headers=headers,
                stream=True,  # Important pour ne pas t√©l√©charger tout le contenu
                timeout=10,
                allow_redirects=True  # Important: suivre les redirections
            )
            
            # Lire juste un peu de contenu pour confirmer l'acc√®s
            for chunk in response.iter_content(chunk_size=1024):
                break
                
            st.write(f"URL finale apr√®s redirection: {response.url}")
            
            if response.status_code == 200:
                size_mb = int(response.headers.get('content-length', 0)) / (1024 * 1024)
                st.success(f"‚úÖ Connexion r√©ussie! Taille du mod√®le: {size_mb:.2f} MB")
                return True
            else:
                st.error(f"‚ùå Erreur HTTP {response.status_code}")
                
                # Afficher des informations de d√©bogage
                with st.expander("D√©tails de l'erreur (pour le d√©pannage)"):
                    st.write({
                        "Code d'√©tat": response.status_code,
                        "URL demand√©e": HF_MODEL_URL,
                        "URL finale": response.url,
                        "En-t√™tes": dict(response.headers),
                        "Token pr√©sent": "Oui" if bool(hf_token) else "Non"
                    })
                return False
    except Exception as e:
        st.error(f"‚ùå Erreur de connexion: {str(e)}")
        with st.expander("D√©tails techniques de l'erreur"):
            st.exception(e)
        return False

# Informations syst√®me pour le d√©bogage
with st.sidebar:
    st.title("Informations syst√®me")
    
    # Afficher les informations avec des √©tiquettes claires
    system_info = {
        "Version Python": platform.python_version(),
        "M√©moire disponible": f"{psutil.virtual_memory().available / (1024 * 1024):.2f} MB",
        "Nombre de CPU": os.cpu_count(),
        "R√©pertoire de travail": os.getcwd()
    }
    
    for label, value in system_info.items():
        st.markdown(f"**{label}:** {value}")

    # Afficher l'URL et le chemin du mod√®le pour d√©bogage
    paths = get_model_paths()
    st.markdown("### Informations mod√®le")
    st.markdown(f"**URL Hugging Face:** {HF_MODEL_URL}")
    st.markdown(f"**Chemin local:** {paths['convnext_model']}")

    # Test de connexion √† Hugging Face avec la nouvelle fonction
    st.button("Tester la connexion √† Hugging Face", help="V√©rifie si l'application peut acc√©der au mod√®le sur Hugging Face", on_click=test_hugging_face_connection)

# Titre principal avec description claire
st.title("ü¶ú Classification d'Images avec ConvNeXtTiny")
st.markdown("""
Cette application permet de classifier des images selon diff√©rentes cat√©gories en utilisant un mod√®le ConvNeXtTiny.

**Comment utiliser cette application:**
1. Choisissez une image (en la t√©l√©chargeant ou en s√©lectionnant un exemple)
2. Le mod√®le analysera automatiquement l'image
3. Les r√©sultats de classification s'afficheront ci-dessous

D√©velopp√© par Mourad JABRI, 2025
""")

def load_example_images():
    """
    Charge les exemples d'images disponibles dans le dossier assets/examples
    
    Returns:
        list: Liste des chemins d'acc√®s aux images exemple
    """
    examples_dir = os.path.join("assets", "examples")
    if not os.path.exists(examples_dir):
        st.warning(f"‚ö†Ô∏è Le dossier d'exemples '{examples_dir}' n'existe pas.")
        # Afficher le contenu du r√©pertoire actuel pour le d√©bogage
        with st.expander("Informations de d√©pannage"):
            st.write("Contenu du r√©pertoire actuel:", os.listdir("."))
        return []
    
    image_files = [f for f in os.listdir(examples_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
    if not image_files:
        st.warning(f"‚ö†Ô∏è Aucune image trouv√©e dans le dossier '{examples_dir}'")
        return []
    
    return [os.path.join(examples_dir, f) for f in image_files]

@st.cache_resource
def load_model():
    """
    Charge le mod√®le de classification et les cat√©gories.
    Cette fonction est mise en cache pour √©viter de recharger le mod√®le √† chaque interaction.
    
    Returns:
        tuple: (mod√®le, dictionnaire des cat√©gories) ou (None, None) en cas d'erreur
    """
    with st.spinner('Chargement du mod√®le en cours. Cela peut prendre quelques instants...'):
        try:
            # Test de connexion √† Hugging Face
            st.info("Test de connexion √† Hugging Face...")
            test_result = test_hugging_face_connection()
            if not test_result:
                st.warning("La connexion √† Hugging Face a √©chou√©, mais nous allons essayer de charger le mod√®le quand m√™me.")

            # Obtention des chemins
            paths = get_model_paths()
            st.write("Chemins recherch√©s pour le mod√®le:", paths)

            # Mesure du temps de chargement du mod√®le
            start_time = time.time()

            # Utilisation de la fonction load_efficientnet_transformer_model qui redirige vers ConvNeXtTiny
            st.info("Chargement du mod√®le ConvNeXtTiny depuis Hugging Face...")
            model = load_efficientnet_transformer_model()

            end_time = time.time()
            loading_time = end_time - start_time

            if model is None:
                st.error("Le mod√®le n'a pas pu √™tre charg√© correctement")

                # V√©rifier si le token est pr√©sent
                hf_token = get_hugging_face_token()
                if not hf_token:
                    st.error("Aucun token Hugging Face trouv√©. Veuillez l'ajouter dans les secrets Streamlit.")
                    st.info("Pour ajouter un token Hugging Face, allez dans les param√®tres de votre application Streamlit Cloud, puis dans l'onglet 'Secrets' et ajoutez: HF_TOKEN = 'votre_token'")

                return None, None

            # V√©rification du mod√®le charg√©
            st.write("### V√©rification du mod√®le charg√©")
            # Afficher les informations dans un format bien organis√©
            model_info = {
                "Nombre de couches": len(model.layers),
                "Format de sortie": str(model.output_shape),
                "Temps de chargement": f"{loading_time:.2f} secondes"
            }
            
            for label, value in model_info.items():
                st.markdown(f"**{label}:** {value}")

            # Afficher le type de mod√®le charg√©
            import tensorflow as tf
            model_size = sum([tf.keras.backend.count_params(w) for w in model.weights])
            st.write(f"**Taille du mod√®le:** {model_size/1000000:.2f} millions de param√®tres")

            if model_size < 10_000_000:  # 10M param√®tres
                st.success("‚úÖ Mod√®le ConvNeXtTiny charg√© avec succ√®s")
            else:
                st.info("‚úÖ Mod√®le standard charg√© avec succ√®s")

            categories = load_categories()
            st.success("Mod√®le et cat√©gories charg√©s avec succ√®s!")
            return model, categories

        except Exception as e:
            st.error(f"Erreur lors du chargement du mod√®le")
            with st.expander("D√©tails techniques de l'erreur"):
                st.error(f"Description d√©taill√©e: {str(e)}")
                st.code(traceback.format_exc())

            # V√©rifier si le token est pr√©sent
            hf_token = get_hugging_face_token()
            if not hf_token:
                st.error("Aucun token Hugging Face trouv√©. Veuillez l'ajouter dans les secrets Streamlit.")
                st.info("Pour ajouter un token Hugging Face, allez dans les param√®tres de votre application Streamlit Cloud, puis dans l'onglet 'Secrets' et ajoutez: HF_TOKEN = 'votre_token'")

            return None, None

# Chargement du mod√®le
model, categories = load_model()

# Interface pour s√©lectionner entre upload et exemples
st.header("S√©lection de l'image")
source_option = st.radio(
    "Comment souhaitez-vous fournir une image?",
    ["T√©l√©charger une image", "Utiliser un exemple"],
    help="Choisissez si vous voulez t√©l√©charger votre propre image ou utiliser une image d'exemple"
)

if source_option == "T√©l√©charger une image":
    # Interface utilisateur pour l'upload d'images
    uploaded_file = st.file_uploader(
        "Choisissez une image √† classifier (JPG, JPEG ou PNG)",
        type=["jpg", "jpeg", "png"],
        help="L'image sera analys√©e par le mod√®le de classification"
    )
    
    if uploaded_file is not None:
        # Traitement de l'image t√©l√©charg√©e
        try:
            image = Image.open(uploaded_file)
            # Afficher l'image avec une description accessible
            st.image(
                image, 
                caption=f"Image t√©l√©charg√©e: {uploaded_file.name}", 
                use_column_width=True,
                output_format="PNG"  # Format stable pour l'affichage
            )
            
            # Pr√©diction
            if model is not None and categories is not None:
                with st.spinner("Classification en cours... Veuillez patienter."):
                    predictions = predict_image(model, image, categories)
                    
                    # Afficher les r√©sultats
                    st.header("R√©sultats de la classification")
                    
                    # Afficher un tableau de r√©sultats textuels pour accessibilit√©
                    st.markdown("### Probabilit√©s par cat√©gorie")
                    results_table = []
                    
                    # Trier les pr√©dictions par probabilit√© d√©croissante
                    sorted_preds = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
                    
                    for category, probability in sorted_preds:
                        results_table.append({
                            "Cat√©gorie": category,
                            "Probabilit√©": f"{probability*100:.2f}%"
                        })
                    
                    st.table(results_table)
                    
                    # Visualisation graphique (avec texte alternatif)
                    st.markdown("### Visualisation graphique")
                    fig = plot_prediction_bars(predictions)
                    st.pyplot(fig)
                    
                    # Ajouter une description textuelle du r√©sultat principal pour accessibilit√©
                    top_category = sorted_preds[0][0]
                    top_probability = sorted_preds[0][1]
                    st.markdown(f"""
                    **R√©sultat principal:** L'image est classifi√©e comme **{top_category}** 
                    avec une probabilit√© de **{top_probability*100:.2f}%**.
                    """)
        except Exception as e:
            st.error(f"Erreur lors du traitement de l'image")
            with st.expander("D√©tails techniques de l'erreur"):
                st.error(f"Description: {str(e)}")
                st.code(traceback.format_exc())
else:
    # Chargement et affichage des exemples
    examples = load_example_images()
    
    if examples:
        # S√©lection d'un exemple avec descriptions accessibles
        example_options = [os.path.basename(ex) for ex in examples]
        selected_example_name = st.selectbox(
            "S√©lectionnez une image exemple",
            example_options,
            help="Choisissez parmi les images d'exemple disponibles"
        )
        
        # Retrouver le chemin complet
        selected_example = next((ex for ex in examples if os.path.basename(ex) == selected_example_name), None)
        
        if selected_example:
            try:
                image = Image.open(selected_example)
                # Afficher l'image avec une description accessible
                st.image(
                    image, 
                    caption=f"Exemple: {os.path.basename(selected_example)}", 
                    use_column_width=True,
                    output_format="PNG"
                )
                
                # Pr√©diction sur l'exemple
                if model is not None and categories is not None:
                    with st.spinner("Classification en cours... Veuillez patienter."):
                        predictions = predict_image(model, image, categories)
                        
                        # Afficher les r√©sultats
                        st.header("R√©sultats de la classification")
                        
                        # Afficher un tableau de r√©sultats textuels pour accessibilit√©
                        st.markdown("### Probabilit√©s par cat√©gorie")
                        results_table = []
                        
                        # Trier les pr√©dictions par probabilit√© d√©croissante
                        sorted_preds = sorted(predictions.items(), key=lambda x: x[1], reverse=True)
                        
                        for category, probability in sorted_preds:
                            results_table.append({
                                "Cat√©gorie": category,
                                "Probabilit√©": f"{probability*100:.2f}%"
                            })
                        
                        st.table(results_table)
                        
                        # Visualisation graphique (avec texte alternatif)
                        st.markdown("### Visualisation graphique")
                        fig = plot_prediction_bars(predictions)
                        st.pyplot(fig)
                        
                        # Ajouter une description textuelle du r√©sultat principal pour accessibilit√©
                        top_category = sorted_preds[0][0]
                        top_probability = sorted_preds[0][1]
                        st.markdown(f"""
                        **R√©sultat principal:** L'image est classifi√©e comme **{top_category}** 
                        avec une probabilit√© de **{top_probability*100:.2f}%**.
                        """)
            except Exception as e:
                st.error(f"Erreur lors du traitement de l'image exemple")
                with st.expander("D√©tails techniques de l'erreur"):
                    st.error(f"Description: {str(e)}")
                    st.code(traceback.format_exc())
    else:
        st.error("Aucun exemple d'image n'a √©t√© trouv√©. Veuillez t√©l√©charger votre propre image.")
        with st.expander("Informations de d√©pannage"):
            st.write("R√©pertoire de travail:", os.getcwd())
            st.write("Contenu du r√©pertoire:", os.listdir("."))
            if os.path.exists("assets"):
                st.write("Contenu du r√©pertoire assets:", os.listdir("assets"))

# Pied de page avec informations compl√©mentaires
st.markdown("---")
st.markdown("""
### √Ä propos de cette application
Cette application de classification d'images utilise un mod√®le ConvNeXtTiny entra√Æn√© sur un dataset Flipkart.
Pour plus d'informations, consultez [le mod√®le sur Hugging Face](https://huggingface.co/mourad42008/convnext-tiny-flipkart-classification).

Pour signaler des probl√®mes ou contribuer, contactez l'auteur.
""")
