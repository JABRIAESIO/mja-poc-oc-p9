import streamlit as st
import os
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import io
import time
import glob
import random
import traceback
import json
import requests
import sys
import platform
import psutil

# Utilise TensorFlow comme backend pour Keras 3
os.environ['KERAS_BACKEND'] = 'tensorflow'

from models.model_loader import load_efficientnet_transformer_model, load_categories, get_model_paths, get_hugging_face_token, HF_MODEL_URL
from models.inference import predict_image, plot_prediction_bars
from utils.preprocessing import preprocess_image_for_convnext, resize_and_pad_image, apply_data_augmentation

# Configuration de la page avec pr√©occupation d'accessibilit√©
st.set_page_config(
    page_title="Classifieur d'Images - Flipkart",
    page_icon="üõí",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ajout de CSS pour am√©liorer l'accessibilit√©
st.markdown("""
<style>
    /* Augmenter le contraste des textes */
    .stMarkdown, .stText, .stHeading, .stButton, .stRadio, h1, h2, h3, p {
        color: #191919 !important;
    }

    /* Augmenter la taille de la police pour une meilleure lisibilit√© */
    .stMarkdown, .stText, p {
        font-size: 16px !important;
    }

    /* Meilleur contraste pour les titres */
    h1, h2, h3, .stHeading {
        font-weight: 600 !important;
    }

    /* Assurer que les liens sont facilement identifiables */
    a {
        color: #0056b3 !important;
        text-decoration: underline !important;
    }

    /* Focus visible pour les √©l√©ments interactifs */
    button:focus, input:focus, select:focus {
        outline: 3px solid #4299e1 !important;
    }

    /* Am√©liorer la visibilit√© des boutons */
    .stButton button {
        font-weight: 500 !important;
        padding: 0.5rem 1rem !important;
    }

    /* Meilleur espacement pour les √©l√©ments de formulaire */
    .stRadio, .stSelectbox, .stFileUploader {
        margin-bottom: 1.5rem !important;
    }
</style>
""", unsafe_allow_html=True)

def test_hugging_face_connection():
    """
    Teste la connexion √† Hugging Face en v√©rifiant l'acc√®s au mod√®le.
    """
    try:
        # Obtenir le token
        hf_token = get_hugging_face_token()

        # Pr√©parer les headers
        headers = {}
        if hf_token:
            headers["Authorization"] = f"Bearer {hf_token}"
            st.info("üîë Token d'authentification trouv√©")
        else:
            st.warning("‚ö†Ô∏è Aucun token d'authentification trouv√©")

        # Faire la requ√™te - Utiliser GET au lieu de HEAD et suivre les redirections
        with st.spinner("Test de connexion en cours. Veuillez patienter..."):
            # Test direct sur le mod√®le avec GET et streaming
            response = requests.get(
                HF_MODEL_URL,
                headers=headers,
                stream=True,  # Important pour ne pas t√©l√©charger tout le contenu
                timeout=10,
                allow_redirects=True  # Important: suivre les redirections
            )

            # Lire juste un peu de contenu pour confirmer l'acc√®s
            for chunk in response.iter_content(chunk_size=1024):
                break

            st.write(f"URL finale apr√®s redirection: {response.url}")

            if response.status_code == 200:
                size_mb = int(response.headers.get('content-length', 0)) / (1024 * 1024)
                st.success(f"‚úÖ Connexion r√©ussie! Taille du mod√®le: {size_mb:.2f} MB")
                return True
            else:
                st.error(f"‚ùå Erreur HTTP {response.status_code}")

                # Afficher des informations de d√©bogage
                with st.expander("D√©tails de l'erreur (pour le d√©pannage)"):
                    st.write({
                        "Code d'√©tat": response.status_code,
                        "URL demand√©e": HF_MODEL_URL,
                        "URL finale": response.url,
                        "En-t√™tes": dict(response.headers),
                        "Token pr√©sent": "Oui" if bool(hf_token) else "Non"
                    })
                return False
    except Exception as e:
        st.error(f"‚ùå Erreur de connexion: {str(e)}")
        with st.expander("D√©tails techniques de l'erreur"):
            st.exception(e)
        return False

def load_example_images():
    """
    Charge les exemples d'images disponibles dans le dossier assets/examples

    Returns:
        list: Liste des chemins d'acc√®s aux images exemple
    """
    examples_dir = os.path.join("assets", "examples")
    if not os.path.exists(examples_dir):
        st.warning(f"‚ö†Ô∏è Le dossier d'exemples '{examples_dir}' n'existe pas.")
        # Afficher le contenu du r√©pertoire actuel pour le d√©bogage
        with st.expander("Informations de d√©pannage"):
            st.write("Contenu du r√©pertoire actuel:", os.listdir("."))
        return []

    image_files = [f for f in os.listdir(examples_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
    if not image_files:
        st.warning(f"‚ö†Ô∏è Aucune image trouv√©e dans le dossier '{examples_dir}'")
        return []

    return [os.path.join(examples_dir, f) for f in image_files]

@st.cache_resource(show_spinner=False)
def load_model():
    """
    Charge le mod√®le de classification et les cat√©gories.
    Cette fonction est mise en cache pour √©viter de recharger le mod√®le √† chaque interaction.

    Returns:
        tuple: (mod√®le, dictionnaire des cat√©gories) ou (None, None) en cas d'erreur
    """
    # Cr√©er un placeholder pour les messages de chargement
    loading_placeholder = st.empty()

    with st.spinner('Chargement du mod√®le en cours. Cela peut prendre quelques instants...'):
        try:
            # Test de connexion √† Hugging Face
            loading_placeholder.info("Test de connexion √† Hugging Face...")
            test_result = test_hugging_face_connection()
            if not test_result:
                loading_placeholder.warning("La connexion √† Hugging Face a √©chou√©, mais nous allons essayer de charger le mod√®le quand m√™me.")

            # Obtention des chemins
            paths = get_model_paths()
            loading_placeholder.info(f"Recherche du mod√®le dans: {paths['convnext_model']}")

            # Mesure du temps de chargement du mod√®le
            start_time = time.time()

            # Utilisation de la fonction load_efficientnet_transformer_model qui redirige vers ConvNeXtTiny
            loading_placeholder.info("Chargement du mod√®le ConvNeXtTiny...")
            model = load_efficientnet_transformer_model(loading_placeholder)

            end_time = time.time()
            loading_time = end_time - start_time

            if model is None:
                loading_placeholder.error("Le mod√®le n'a pas pu √™tre charg√© correctement")

                # V√©rifier si le token est pr√©sent
                hf_token = get_hugging_face_token()
                if not hf_token:
                    loading_placeholder.error("Aucun token Hugging Face trouv√©. Veuillez l'ajouter dans les secrets Streamlit.")
                    loading_placeholder.info("Pour ajouter un token Hugging Face, allez dans les param√®tres de votre application Streamlit Cloud, puis dans l'onglet 'Secrets' et ajoutez: HF_TOKEN = 'votre_token'")

                return None, None

            # Information sur le chargement r√©ussi
            loading_placeholder.success(f"‚úÖ Mod√®le charg√© avec succ√®s en {loading_time:.2f} secondes!")

            # Chargement des cat√©gories
            categories = load_categories()
            loading_placeholder.success("Cat√©gories charg√©es avec succ√®s!")

            # Effacer le placeholder une fois le chargement termin√©
            loading_placeholder.empty()

            return model, categories

        except Exception as e:
            loading_placeholder.error(f"Erreur lors du chargement du mod√®le")
            with st.expander("D√©tails techniques de l'erreur"):
                st.error(f"Description d√©taill√©e: {str(e)}")
                st.code(traceback.format_exc())

            # V√©rifier si le token est pr√©sent
            hf_token = get_hugging_face_token()
            if not hf_token:
                loading_placeholder.error("Aucun token Hugging Face trouv√©. Veuillez l'ajouter dans les secrets Streamlit.")
                loading_placeholder.info("Pour ajouter un token Hugging Face, allez dans les param√®tres de votre application Streamlit Cloud, puis dans l'onglet 'Secrets' et ajoutez: HF_TOKEN = 'votre_token'")

            return None, None

def main():
    # Informations syst√®me pour le d√©bogage
    with st.sidebar:
        st.title("Informations syst√®me")

        # Afficher les informations avec des √©tiquettes claires
        system_info = {
            "Version Python": platform.python_version(),
            "M√©moire disponible": f"{psutil.virtual_memory().available / (1024 * 1024):.2f} MB",
            "Nombre de CPU": os.cpu_count(),
            "R√©pertoire de travail": os.getcwd()
        }

        for label, value in system_info.items():
            st.markdown(f"**{label}:** {value}")

        # Afficher l'URL et le chemin du mod√®le pour d√©bogage
        paths = get_model_paths()
        st.markdown("### Informations mod√®le")
        st.markdown(f"**URL Hugging Face:** {HF_MODEL_URL}")
        st.markdown(f"**Chemin local:** {paths['convnext_model']}")

        # Test de connexion √† Hugging Face avec la nouvelle fonction
        if st.button("Tester la connexion √† Hugging Face", help="V√©rifie si l'application peut acc√©der au mod√®le sur Hugging Face"):
            test_hugging_face_connection()

    # Titre principal avec description claire
    st.title("üõí Classifieur d'Images - Flipkart")
    st.markdown("""
    Cette application permet de classifier des images selon diff√©rentes cat√©gories en utilisant un mod√®le ConvNeXtTiny.

    **Comment utiliser cette application:**
    1. T√©l√©chargez une image de produit
    2. Le mod√®le analysera automatiquement l'image
    3. Les r√©sultats de classification s'afficheront ci-dessous

    D√©velopp√© dans le cadre du projet 9 de la formation OpenClassrooms "Machine Learning Engineer".
    """)

    # Chargement du mod√®le
    model, categories = load_model()
    # d√©bug du chargement du model
	if model is not None and categories is not None:
        st.sidebar.success("‚úÖ Mod√®le et cat√©gories charg√©s")
        st.sidebar.info(f"Type mod√®le: {type(model)}")
        st.sidebar.info(f"Nombre cat√©gories: {len(categories)}")
    else:
        st.sidebar.error("‚ùå Probl√®me de chargement d√©tect√©")
        if model is None:
            st.sidebar.error("Mod√®le = None")
        if categories is None:
            st.sidebar.error("Categories = None")

    # Interface pour s√©lectionner entre upload et exemples
    st.header("S√©lection de l'image")
    source_option = st.radio(
        "Comment souhaitez-vous fournir une image?",
        ["T√©l√©charger une image", "Utiliser un exemple"],
        help="Choisissez si vous voulez t√©l√©charger votre propre image ou utiliser une image d'exemple"
    )

    if source_option == "T√©l√©charger une image":
        # Interface utilisateur pour l'upload d'images
        uploaded_file = st.file_uploader(
            "Choisissez une image √† classifier (JPG, JPEG ou PNG)",
            type=["jpg", "jpeg", "png"],
            help="L'image sera analys√©e par le mod√®le de classification"
        )

        if uploaded_file is not None:
            # Traitement de l'image t√©l√©charg√©e
            try:
                image = Image.open(uploaded_file)
                # Afficher l'image avec une description accessible
                st.image(
                    image,
                    caption=f"Image t√©l√©charg√©e: {uploaded_file.name}",
                    width=400,
                    output_format="PNG"  # Format stable pour l'affichage
                )

                # Pr√©diction
                if model is not None and categories is not None:
                    with st.spinner("Classification en cours... Veuillez patienter."):
                        # Utilisation de la fonction predict_image de models.inference qui g√®re diff√©rents types de mod√®les
                        result = predict_image(model, image, categories)

                        if "error" in result:
                            st.error(f"Erreur lors de la pr√©diction: {result['error']}")
                            with st.expander("D√©tails de l'erreur"):
                                st.code(result.get("error_trace", "Pas de d√©tails suppl√©mentaires disponibles"))
                        else:
                            # Extraction des pr√©dictions
                            predicted_class = result["predicted_class"]
                            confidence = result["confidence"]
                            all_predictions = result["all_predictions"]

                            # Afficher les r√©sultats
                            col1, col2 = st.columns(2)

                            with col1:
                                st.subheader("R√©sultat de la classification")
                                st.success(f"Cat√©gorie pr√©dite: **{predicted_class}**")
                                st.progress(confidence)
                                st.info(f"Confiance: {confidence*100:.2f}%")

                                # Afficher un tableau de r√©sultats textuels pour accessibilit√©
                                st.markdown("### Probabilit√©s par cat√©gorie")
                                results_table = []

                                for pred in all_predictions:
                                    results_table.append({
                                        "Cat√©gorie": pred["class_name"],
                                        "Probabilit√©": f"{pred['probability']*100:.2f}%"
                                    })

                                st.table(results_table)

                            with col2:
                                # Visualisation graphique
                                st.markdown("### Visualisation graphique")
                                # Cr√©er un dictionnaire pour la fonction plot_prediction_bars
                                prediction_dict = {pred["class_name"]: pred["probability"] for pred in all_predictions}
                                fig = plot_prediction_bars(prediction_dict)
                                st.pyplot(fig)

                            # Information sur les performances
                            with st.expander("Informations sur les performances"):
                                st.markdown(f"""
                                - **Temps de pr√©traitement**: {result['preprocess_time']*1000:.2f} ms
                                - **Temps d'inf√©rence**: {result['inference_time']*1000:.2f} ms
                                - **Temps total**: {result['total_time']*1000:.2f} ms
                                """)
            except Exception as e:
                st.error(f"Erreur lors du traitement de l'image")
                with st.expander("D√©tails techniques de l'erreur"):
                    st.error(f"Description: {str(e)}")
                    st.code(traceback.format_exc())
    else:
        # Chargement et affichage des exemples
        examples = load_example_images()

        if examples:
            # S√©lection d'un exemple avec descriptions accessibles
            example_options = [os.path.basename(ex) for ex in examples]
            selected_example_name = st.selectbox(
                "S√©lectionnez une image exemple",
                example_options,
                help="Choisissez parmi les images d'exemple disponibles"
            )

            # Retrouver le chemin complet
            selected_example = next((ex for ex in examples if os.path.basename(ex) == selected_example_name), None)

            if selected_example:
                try:
                    image = Image.open(selected_example)
                    # Afficher l'image avec une description accessible
                    st.image(
                        image,
                        caption=f"Exemple: {os.path.basename(selected_example)}",
                        width=400,
                        output_format="PNG"
                    )

                    # Pr√©diction sur l'exemple
                    if model is not None and categories is not None:
                        with st.spinner("Classification en cours... Veuillez patienter."):
                            # Utilisation de la fonction predict_image de models.inference
                            result = predict_image(model, image, categories)

                            if "error" in result:
                                st.error(f"Erreur lors de la pr√©diction: {result['error']}")
                                with st.expander("D√©tails de l'erreur"):
                                    st.code(result.get("error_trace", "Pas de d√©tails suppl√©mentaires disponibles"))
                            else:
                                # Extraction des pr√©dictions
                                predicted_class = result["predicted_class"]
                                confidence = result["confidence"]
                                all_predictions = result["all_predictions"]

                                # Afficher les r√©sultats
                                col1, col2 = st.columns(2)

                                with col1:
                                    st.subheader("R√©sultat de la classification")
                                    st.success(f"Cat√©gorie pr√©dite: **{predicted_class}**")
                                    st.progress(confidence)
                                    st.info(f"Confiance: {confidence*100:.2f}%")

                                    # Afficher un tableau de r√©sultats textuels pour accessibilit√©
                                    st.markdown("### Probabilit√©s par cat√©gorie")
                                    results_table = []

                                    for pred in all_predictions:
                                        results_table.append({
                                            "Cat√©gorie": pred["class_name"],
                                            "Probabilit√©": f"{pred['probability']*100:.2f}%"
                                        })

                                    st.table(results_table)

                                with col2:
                                    # Visualisation graphique
                                    st.markdown("### Visualisation graphique")
                                    # Cr√©er un dictionnaire pour la fonction plot_prediction_bars
                                    prediction_dict = {pred["class_name"]: pred["probability"] for pred in all_predictions}
                                    fig = plot_prediction_bars(prediction_dict)
                                    st.pyplot(fig)

                                # Information sur les performances
                                with st.expander("Informations sur les performances"):
                                    st.markdown(f"""
                                    - **Temps de pr√©traitement**: {result['preprocess_time']*1000:.2f} ms
                                    - **Temps d'inf√©rence**: {result['inference_time']*1000:.2f} ms
                                    - **Temps total**: {result['total_time']*1000:.2f} ms
                                    """)
                except Exception as e:
                    st.error(f"Erreur lors du traitement de l'image exemple")
                    with st.expander("D√©tails techniques de l'erreur"):
                        st.error(f"Description: {str(e)}")
                        st.code(traceback.format_exc())
        else:
            st.warning("Aucun exemple d'image n'a √©t√© trouv√©. Veuillez t√©l√©charger votre propre image.")
            with st.expander("Informations de d√©pannage"):
                st.write("R√©pertoire de travail:", os.getcwd())
                st.write("Contenu du r√©pertoire:", os.listdir("."))
                if os.path.exists("assets"):
                    st.write("Contenu du r√©pertoire assets:", os.listdir("assets"))

    # Pied de page avec informations compl√©mentaires
    st.markdown("---")
    st.markdown("""
    ### √Ä propos de cette application
    Cette application de classification d'images utilise un mod√®le ConvNeXtTiny entra√Æn√© sur un dataset Flipkart.
    Elle a √©t√© d√©velopp√©e dans le cadre du projet 9 de la formation OpenClassrooms "Machine Learning Engineer".

    Pour plus d'informations sur le mod√®le, consultez [Hugging Face](https://huggingface.co/mourad42008/convnext-tiny-flipkart-classification).
    """)
# date 11/05/2025 21h49
# Point d'entr√©e principal
if __name__ == "__main__":
    main()
